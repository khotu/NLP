{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Natural language processing (NLP) is a field of computer science, artificial intelligence and computational \\\n",
    "linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, \\\n",
    "concerned with programming computers to fruitfully process large natural language corpora.’, \\\n",
    "‘Challenges in natural language processing frequently involve natural language understanding, natural language generation \\\n",
    "(frequently from formal, machine-readable logical forms), connecting language and machine perception, managing human-computer\\\n",
    "dialog systems, or some combination thereof.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text_token = nltk.tokenize.word_tokenize(text)\n",
    "    remove_punctu = [w for w in text_token if w not in string.punctuation]\n",
    "    stop_words = stopwords.words('english')\n",
    "    remove_stop_word = [w for w in remove_punctu if w not in stop_words]\n",
    "    lower_text = [w.lower() for w in remove_stop_word if len(w)>2]\n",
    "    lemmaed_text = [WordNetLemmatizer().lemmatize(w) for w in lower_text]\n",
    "    return ' '.join(lemmaed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_txt = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_txt = nltk.tag.pos_tag(nltk.tokenize.word_tokenize(processed_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('nlp', 'JJ'), ('field', 'NN'), ('computer', 'NN'), ('science', 'NN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('computational', 'JJ'), ('linguistics', 'NNS'), ('concerned', 'JJ'), ('interaction', 'NN'), ('computer', 'NN'), ('human', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('particular', 'JJ'), ('concerned', 'VBD'), ('programming', 'VBG'), ('computer', 'NN'), ('fruitfully', 'RB'), ('process', 'JJ'), ('large', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('corpora', 'NN'), ('.', '.'), ('challenge', 'VB'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('frequently', 'RB'), ('involve', 'VBP'), ('natural', 'JJ'), ('language', 'NN'), ('understanding', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('generation', 'NN'), ('frequently', 'RB'), ('formal', 'JJ'), ('machine-readable', 'JJ'), ('logical', 'JJ'), ('form', 'NN'), ('connecting', 'VBG'), ('language', 'NN'), ('machine', 'NN'), ('perception', 'NN'), ('managing', 'VBG'), ('human-computerdialog', 'JJ'), ('system', 'NN'), ('combination', 'NN'), ('thereof', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One of the main goals of chunking is to group into what are known as \"noun phrases.\" These are phrases of one or more words that contain a noun, maybe some descriptive words, maybe a verb, and maybe something like an adverb. The idea is to group nouns with the words that are in relation to them."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### POS tag list:\n",
    "\n",
    "CC coordinating conjunction\n",
    "CD cardinal digit\n",
    "DT determiner\n",
    "EX existential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "FW foreign word\n",
    "IN preposition/subordinating conjunction\n",
    "JJ adjective 'big'\n",
    "JJR adjective, comparative 'bigger'\n",
    "JJS adjective, superlative 'biggest'\n",
    "LS list marker 1)\n",
    "MD modal could, will\n",
    "NN noun, singular 'desk'\n",
    "NNS noun plural 'desks'\n",
    "NNP proper noun, singular 'Harrison'\n",
    "NNPS proper noun, plural 'Americans'\n",
    "PDT predeterminer 'all the kids'\n",
    "POS possessive ending parent's\n",
    "PRP personal pronoun I, he, she\n",
    "PRP$ possessive pronoun my, his, hers\n",
    "RB adverb very, silently,\n",
    "RBR adverb, comparative better\n",
    "RBS adverb, superlative best\n",
    "RP particle give up\n",
    "TO to go 'to' the store.\n",
    "UH interjection errrrrrrrm\n",
    "VB verb, base form take\n",
    "VBD verb, past tense took\n",
    "VBG verb, gerund/present participle taking\n",
    "VBN verb, past participle taken\n",
    "VBP verb, sing. present, non-3d take\n",
    "VBZ verb, 3rd person sing. present takes\n",
    "WDT wh-determiner which\n",
    "WP wh-pronoun who, what\n",
    "WP$ possessive wh-pronoun whose\n",
    "WRB wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkgram = r''' Chunk : {<RB.?>*<VB.?>*<JJ.?>*<NN.?>*}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkparser = nltk.RegexpParser(chunkgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked  = chunkparser.parse(tagged_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Chunk natural/JJ language/NN processing/NN)\n",
      "  (Chunk nlp/JJ field/NN computer/NN science/NN)\n",
      "  (Chunk artificial/JJ intelligence/NN)\n",
      "  (Chunk computational/JJ linguistics/NNS)\n",
      "  (Chunk concerned/JJ interaction/NN computer/NN)\n",
      "  (Chunk human/JJ natural/JJ language/NN)\n",
      "  (Chunk particular/JJ)\n",
      "  (Chunk concerned/VBD programming/VBG computer/NN)\n",
      "  (Chunk\n",
      "    fruitfully/RB\n",
      "    process/JJ\n",
      "    large/JJ\n",
      "    natural/JJ\n",
      "    language/NN\n",
      "    corpora/NN)\n",
      "  ./.\n",
      "  (Chunk challenge/VB natural/JJ language/NN processing/NN)\n",
      "  (Chunk frequently/RB involve/VBP natural/JJ language/NN)\n",
      "  (Chunk understanding/JJ natural/JJ language/NN generation/NN)\n",
      "  (Chunk\n",
      "    frequently/RB\n",
      "    formal/JJ\n",
      "    machine-readable/JJ\n",
      "    logical/JJ\n",
      "    form/NN)\n",
      "  (Chunk connecting/VBG language/NN machine/NN perception/NN)\n",
      "  (Chunk\n",
      "    managing/VBG\n",
      "    human-computerdialog/JJ\n",
      "    system/NN\n",
      "    combination/NN\n",
      "    thereof/NN))\n"
     ]
    }
   ],
   "source": [
    "print(chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You may find that, after a lot of chunking, you have some words in your chunk you still do not want, but you have no idea how to get rid of them by chunking. You may find that chinking is your solution.\n",
    "\n",
    "#### Chinking is a lot like chunking, it is basically a way for you to remove a chunk from a chunk. The chunk that you remove from your chunk is your chink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkgrammer = r''' Chunk : {<.*>+}\n",
    "                           }<VB.?>*<NN>{ '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkparser = nltk.RegexpParser(chunkgrammer)\n",
    "chunked  = chunkparser.parse(tagged_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Chunk natural/JJ)\n",
      "  language/NN\n",
      "  processing/NN\n",
      "  (Chunk nlp/JJ)\n",
      "  field/NN\n",
      "  computer/NN\n",
      "  science/NN\n",
      "  (Chunk artificial/JJ)\n",
      "  intelligence/NN\n",
      "  (Chunk computational/JJ linguistics/NNS concerned/JJ)\n",
      "  interaction/NN\n",
      "  computer/NN\n",
      "  (Chunk human/JJ natural/JJ)\n",
      "  language/NN\n",
      "  (Chunk particular/JJ)\n",
      "  concerned/VBD\n",
      "  programming/VBG\n",
      "  computer/NN\n",
      "  (Chunk fruitfully/RB process/JJ large/JJ natural/JJ)\n",
      "  language/NN\n",
      "  corpora/NN\n",
      "  (Chunk ./. challenge/VB natural/JJ)\n",
      "  language/NN\n",
      "  processing/NN\n",
      "  (Chunk frequently/RB involve/VBP natural/JJ)\n",
      "  language/NN\n",
      "  (Chunk understanding/JJ natural/JJ)\n",
      "  language/NN\n",
      "  generation/NN\n",
      "  (Chunk frequently/RB formal/JJ machine-readable/JJ logical/JJ)\n",
      "  form/NN\n",
      "  connecting/VBG\n",
      "  language/NN\n",
      "  machine/NN\n",
      "  perception/NN\n",
      "  (Chunk managing/VBG human-computerdialog/JJ)\n",
      "  system/NN\n",
      "  combination/NN\n",
      "  thereof/NN)\n"
     ]
    }
   ],
   "source": [
    "print(chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
