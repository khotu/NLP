{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "import bs4\n",
    "import urllib.request\n",
    "import re\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Machine_learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = urllib.request.urlopen(url)\n",
    "raw_data = raw_data.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_html = bs4.BeautifulSoup(raw_data, 'html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = article_html.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = \" \"\n",
    "for para in paragraphs:\n",
    "    article_text += para.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunny\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Possible nested set at position 1\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "article_text = re.sub(r\"[[0-9]*]\", \"\", article_text)\n",
    "article_text = re.sub(r\":\\d*\", \"\", article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = re.sub(r\"\\s+\", \" \", article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks. Machine learning is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning. In its application across business problems, machine learning is also referred to as '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_sentences = nltk.sent_tokenize(article_text)\n",
    "article_words = nltk.word_tokenize(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnlemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def perform_lemmatization(tokens):\n",
    "    return [wnlemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "punctuation_removal = dict((ord(punctuation), None) for punctuation in string.punctuation)\n",
    "\n",
    "def get_processed_text(document):\n",
    "    return perform_lemmatization(nltk.word_tokenize(document.lower().translate(punctuation_removal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting_inputs = (\"hey\", \"good morning\", \"good evening\", \"morning\", \"evening\", \"hi\",\"hello\", \"whatsup\")\n",
    "greeting_responses = [\"hey\", \"hey hows you?\", \"hello, how you doing\", \"hello\", \"Welcome, I am good and you\"]\n",
    "\n",
    "def generate_greeting_responce(greeting):\n",
    "    for token in greeting.split():\n",
    "        if token.lower() in greeting_inputs:\n",
    "            return random.choice(greeting_responses).title()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunny\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "word_vector = TfidfVectorizer(tokenizer=get_processed_text, stop_words=\"english\")\n",
    "all_words_vector = word_vector.fit_transform(article_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vocabulary 1326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(262, 1326)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"length of vocabulary\", len(word_vector.get_feature_names()))\n",
    "all_words_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_input):\n",
    "    robo_response = \"\"\n",
    "    user_text = user_input.lower()\n",
    "    user_text_vector = word_vector.transform([user_text])\n",
    "    similarty_vector_value = cosine_similarity(user_text_vector, all_words_vector)\n",
    "    similar_sentence_number = similarty_vector_value.argsort()[0][-1]\n",
    "    \n",
    "    similarty_score = similarty_vector_value.flatten()\n",
    "    similarty_score.sort()\n",
    "    similar_score = similarty_score[-1]\n",
    "#     print(similarty_score)\n",
    "    \n",
    "    if similar_score == 0.:\n",
    "        robo_response = robo_response + \"I am sorry, I could not understand you.\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response + article_sentences[similar_sentence_number]\n",
    "        return robo_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am your friend Robo. You can ask me any question regarding machine learning : \n",
      "User : \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robo : Hello, How You Doing\n",
      "User : \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " tell me something about machine learning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robo : A representative book of the machine learning research during the 1960s was the Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.\n",
      "User : \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " pattern classification >\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robo : A representative book of the machine learning research during the 1960s was the Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.\n",
      "User : \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is pattern classification?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robo : A representative book of the machine learning research during the 1960s was the Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.\n",
      "User : \n"
     ]
    }
   ],
   "source": [
    "continue_dialog = True\n",
    "print(\"Hello, I am your friend Robo. You can ask me any question regarding machine learning : \")\n",
    "while continue_dialog:\n",
    "    print(\"User : \")\n",
    "    user_input = input()\n",
    "    user_text = user_input.strip().lower()\n",
    "    \n",
    "    if user_text == \"bye\":\n",
    "        continue_dialog = False\n",
    "        print(\"Robo : Good bye and take care of yourself...\")\n",
    "    else:\n",
    "        if user_text==\"thanks\" or user_text==\"thank you very much\" or user_text==\"thank you\" :\n",
    "            continue_dialog = False\n",
    "            print(\"Robo : Thank you, Most Welcome \")\n",
    "        elif user_text == 'hmmmmmm' or user_text == 'hmm'or user_text == 'ok' or user_text == 'okay':\n",
    "            print(\"Robo : Hmmm..\")\n",
    "        else:\n",
    "            if generate_greeting_responce(user_text) != None:\n",
    "                print(\"Robo : \"+generate_greeting_responce(user_text))\n",
    "            else:\n",
    "                print(\"Robo : \" + generate_response(user_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
