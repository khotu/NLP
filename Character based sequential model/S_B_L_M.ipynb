{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(filename):\n",
    "    file_open = open(file=filename, mode='r')\n",
    "    text = file_open.read()\n",
    "    file_open.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(sequence, filename):\n",
    "    data = \"\\n\".join(sequence)\n",
    "    new_file = open(filename, mode='w')\n",
    "    new_file.write(data)\n",
    "    new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sing a song of sixpence,\\nA pocket full of rye.\\nFour and twenty blackbirds,\\nBaked in a pie.\\nWhen the pie was opened\\nThe birds began to sing;\\nWasn't that a dainty dish,\\nTo set before the king.\\nThe king was in his counting house,\\nCounting out his money;\\nThe queen was in the parlour,\\nEating bread and honey.\\nThe maid was in the garden,\\nHanging out the clothes,\\nWhen down came a blackbird\\nAnd pecked off her nose.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = load_text('rhyme.txt')\n",
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = raw_text.split()\n",
    "raw_text = \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sing a song of sixpence, A pocket full of rye. Four and twenty blackbirds, Baked in a pie. When the pie was opened The birds began to sing; Wasn't that a dainty dish, To set before the king. The king was in his counting house, Counting out his money; The queen was in the parlour, Eating bread and honey. The maid was in the garden, Hanging out the clothes, When down came a blackbird And pecked off her nose.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### we have a long list of characters, we can create our input-output sequences used to train the model. Each input sequence will be 10 characters with one output character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = []\n",
    "for i in range(len(raw_text)-10):\n",
    "    seq = raw_text[i:i+11]\n",
    "    sequence.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence)\n",
    "# sequence[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(sequence, 'char_sequence_rhyme.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a song of s', ' song of si', 'song of six', 'ong of sixp', 'ng of sixpe']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = load_text('char_sequence_rhyme.txt')\n",
    "\n",
    "line_seprate = raw_text.split('\\n')\n",
    "line_seprate[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "\n",
    "mapped_char = dict((char, index) for index, char in enumerate(chars))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [[mapped_char[char] for char in line] for line in line_seprate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15, 1, 32, 28, 27, 21, 1, 28, 20, 1, 32],\n",
       " [1, 32, 28, 27, 21, 1, 28, 20, 1, 32, 23],\n",
       " [32, 28, 27, 21, 1, 28, 20, 1, 32, 23, 36],\n",
       " [28, 27, 21, 1, 28, 20, 1, 32, 23, 36, 29],\n",
       " [27, 21, 1, 28, 20, 1, 32, 23, 36, 29, 19]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split Input and output \n",
    "sequences = np.array(sequences)\n",
    "\n",
    "X, y = sequences[:,:-1], sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import pickle\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 10, 38)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_X = np.array([to_categorical(x, len(mapped_char)) for x in X])\n",
    "input_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 399 - Number of document \n",
    "### 10 - each document have 10 word.\n",
    "### 38 - vectorization of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 38)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_y = to_categorical(y, len(mapped_char))\n",
    "input_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_X):\n",
    "    model = Sequential()\n",
    "    model.add(layers.LSTM(units=75, input_shape=(input_X.shape[1], input_X.shape[2]), \n",
    "                         kernel_initializer='uniform', unit_forget_bias=True, \n",
    "                         kernel_regularizer = regularizers.l2(l=0.0001), dropout = 0.3, return_sequences=True ))\n",
    "    \n",
    "    model.add(layers.LSTM(units=50, input_shape=(input_X.shape[1], input_X.shape[2]), \n",
    "                         kernel_initializer='uniform', unit_forget_bias=True, \n",
    "                         kernel_regularizer = regularizers.l2(l=0.0001), dropout = 0.3, ))\n",
    "    \n",
    "    model.add(layers.Dense(units=50,activation='relu', ))\n",
    "    \n",
    "    model.add(layers.Dense(units=len(mapped_char), activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss=\"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 10, 75)            34200     \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 50)                25200     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 38)                1938      \n",
      "=================================================================\n",
      "Total params: 63,888\n",
      "Trainable params: 63,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model(input_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 359 samples, validate on 40 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 3.5335 - accuracy: 0.1671 - val_loss: 3.3247 - val_accuracy: 0.1750\n",
      "Epoch 2/100\n",
      " - 1s - loss: 3.1899 - accuracy: 0.1922 - val_loss: 3.2559 - val_accuracy: 0.1750\n",
      "Epoch 3/100\n",
      " - 1s - loss: 3.1176 - accuracy: 0.1922 - val_loss: 3.2326 - val_accuracy: 0.1750\n",
      "Epoch 4/100\n",
      " - 1s - loss: 3.0887 - accuracy: 0.1922 - val_loss: 3.2446 - val_accuracy: 0.1750\n",
      "Epoch 5/100\n",
      " - 1s - loss: 3.0434 - accuracy: 0.1922 - val_loss: 3.2364 - val_accuracy: 0.1750\n",
      "Epoch 6/100\n",
      " - 1s - loss: 3.0481 - accuracy: 0.1922 - val_loss: 3.2263 - val_accuracy: 0.1750\n",
      "Epoch 7/100\n",
      " - 1s - loss: 3.0377 - accuracy: 0.1922 - val_loss: 3.1906 - val_accuracy: 0.1750\n",
      "Epoch 8/100\n",
      " - 1s - loss: 3.0125 - accuracy: 0.1922 - val_loss: 3.2164 - val_accuracy: 0.1750\n",
      "Epoch 9/100\n",
      " - 1s - loss: 3.0142 - accuracy: 0.1922 - val_loss: 3.2473 - val_accuracy: 0.1750\n",
      "Epoch 10/100\n",
      " - 1s - loss: 3.0196 - accuracy: 0.1922 - val_loss: 3.2233 - val_accuracy: 0.1750\n",
      "Epoch 11/100\n",
      " - 1s - loss: 3.0264 - accuracy: 0.1922 - val_loss: 3.2305 - val_accuracy: 0.1750\n",
      "Epoch 12/100\n",
      " - 1s - loss: 3.0249 - accuracy: 0.1922 - val_loss: 3.2444 - val_accuracy: 0.1750\n",
      "Epoch 13/100\n",
      " - 1s - loss: 3.0116 - accuracy: 0.1922 - val_loss: 3.2736 - val_accuracy: 0.1750\n",
      "Epoch 14/100\n",
      " - 1s - loss: 3.0241 - accuracy: 0.1922 - val_loss: 3.2607 - val_accuracy: 0.1750\n",
      "Epoch 15/100\n",
      " - 1s - loss: 3.0021 - accuracy: 0.1922 - val_loss: 3.2278 - val_accuracy: 0.1750\n",
      "Epoch 16/100\n",
      " - 1s - loss: 3.0106 - accuracy: 0.1922 - val_loss: 3.2426 - val_accuracy: 0.1750\n",
      "Epoch 17/100\n",
      " - 1s - loss: 3.0015 - accuracy: 0.1922 - val_loss: 3.2397 - val_accuracy: 0.1750\n",
      "Epoch 18/100\n",
      " - 1s - loss: 3.0085 - accuracy: 0.1922 - val_loss: 3.2308 - val_accuracy: 0.1750\n",
      "Epoch 19/100\n",
      " - 1s - loss: 3.0062 - accuracy: 0.1922 - val_loss: 3.2434 - val_accuracy: 0.1750\n",
      "Epoch 20/100\n",
      " - 1s - loss: 2.9957 - accuracy: 0.1922 - val_loss: 3.2304 - val_accuracy: 0.1750\n",
      "Epoch 21/100\n",
      " - 1s - loss: 3.0050 - accuracy: 0.1922 - val_loss: 3.2321 - val_accuracy: 0.1750\n",
      "Epoch 22/100\n",
      " - 1s - loss: 3.0090 - accuracy: 0.1922 - val_loss: 3.2398 - val_accuracy: 0.1750\n",
      "Epoch 23/100\n",
      " - 1s - loss: 3.0048 - accuracy: 0.1922 - val_loss: 3.2229 - val_accuracy: 0.1750\n",
      "Epoch 24/100\n",
      " - 1s - loss: 3.0050 - accuracy: 0.1922 - val_loss: 3.2293 - val_accuracy: 0.1750\n",
      "Epoch 25/100\n",
      " - 1s - loss: 3.0044 - accuracy: 0.1922 - val_loss: 3.2241 - val_accuracy: 0.1750\n",
      "Epoch 26/100\n",
      " - 1s - loss: 2.9902 - accuracy: 0.1922 - val_loss: 3.2366 - val_accuracy: 0.1750\n",
      "Epoch 27/100\n",
      " - 1s - loss: 2.9951 - accuracy: 0.1922 - val_loss: 3.2493 - val_accuracy: 0.1750\n",
      "Epoch 28/100\n",
      " - 1s - loss: 2.9873 - accuracy: 0.1922 - val_loss: 3.2769 - val_accuracy: 0.1750\n",
      "Epoch 29/100\n",
      " - 1s - loss: 2.9883 - accuracy: 0.1922 - val_loss: 3.2579 - val_accuracy: 0.1750\n",
      "Epoch 30/100\n",
      " - 1s - loss: 2.9919 - accuracy: 0.1922 - val_loss: 3.2674 - val_accuracy: 0.1750\n",
      "Epoch 31/100\n",
      " - 1s - loss: 2.9974 - accuracy: 0.1922 - val_loss: 3.2317 - val_accuracy: 0.1750\n",
      "Epoch 32/100\n",
      " - 1s - loss: 2.9911 - accuracy: 0.1922 - val_loss: 3.2373 - val_accuracy: 0.1750\n",
      "Epoch 33/100\n",
      " - 1s - loss: 2.9847 - accuracy: 0.1922 - val_loss: 3.2163 - val_accuracy: 0.1750\n",
      "Epoch 34/100\n",
      " - 1s - loss: 2.9908 - accuracy: 0.1922 - val_loss: 3.2285 - val_accuracy: 0.1750\n",
      "Epoch 35/100\n",
      " - 1s - loss: 2.9690 - accuracy: 0.1922 - val_loss: 3.2533 - val_accuracy: 0.1750\n",
      "Epoch 36/100\n",
      " - 1s - loss: 2.9995 - accuracy: 0.1922 - val_loss: 3.2378 - val_accuracy: 0.1750\n",
      "Epoch 37/100\n",
      " - 1s - loss: 2.9642 - accuracy: 0.1922 - val_loss: 3.2266 - val_accuracy: 0.1750\n",
      "Epoch 38/100\n",
      " - 1s - loss: 2.9885 - accuracy: 0.1922 - val_loss: 3.2325 - val_accuracy: 0.1750\n",
      "Epoch 39/100\n",
      " - 1s - loss: 2.9902 - accuracy: 0.1922 - val_loss: 3.2770 - val_accuracy: 0.1750\n",
      "Epoch 40/100\n",
      " - 1s - loss: 2.9707 - accuracy: 0.1922 - val_loss: 3.2365 - val_accuracy: 0.1750\n",
      "Epoch 41/100\n",
      " - 1s - loss: 2.9826 - accuracy: 0.1922 - val_loss: 3.2183 - val_accuracy: 0.1750\n",
      "Epoch 42/100\n",
      " - 1s - loss: 2.9743 - accuracy: 0.1922 - val_loss: 3.2167 - val_accuracy: 0.1750\n",
      "Epoch 43/100\n",
      " - 1s - loss: 2.9677 - accuracy: 0.1922 - val_loss: 3.2418 - val_accuracy: 0.1750\n",
      "Epoch 44/100\n",
      " - 1s - loss: 2.9643 - accuracy: 0.1922 - val_loss: 3.2273 - val_accuracy: 0.1750\n",
      "Epoch 45/100\n",
      " - 1s - loss: 2.9782 - accuracy: 0.1922 - val_loss: 3.2043 - val_accuracy: 0.1750\n",
      "Epoch 46/100\n",
      " - 1s - loss: 2.9486 - accuracy: 0.1922 - val_loss: 3.2161 - val_accuracy: 0.1750\n",
      "Epoch 47/100\n",
      " - 1s - loss: 2.9516 - accuracy: 0.1922 - val_loss: 3.2115 - val_accuracy: 0.1750\n",
      "Epoch 48/100\n",
      " - 1s - loss: 2.9597 - accuracy: 0.1922 - val_loss: 3.2059 - val_accuracy: 0.1750\n",
      "Epoch 49/100\n",
      " - 1s - loss: 2.9602 - accuracy: 0.1922 - val_loss: 3.1814 - val_accuracy: 0.1750\n",
      "Epoch 50/100\n",
      " - 1s - loss: 2.9390 - accuracy: 0.1922 - val_loss: 3.2026 - val_accuracy: 0.1750\n",
      "Epoch 51/100\n",
      " - 1s - loss: 2.9506 - accuracy: 0.1922 - val_loss: 3.1724 - val_accuracy: 0.1750\n",
      "Epoch 52/100\n",
      " - 1s - loss: 2.9432 - accuracy: 0.1922 - val_loss: 3.1831 - val_accuracy: 0.1750\n",
      "Epoch 53/100\n",
      " - 1s - loss: 2.9326 - accuracy: 0.1922 - val_loss: 3.1801 - val_accuracy: 0.1750\n",
      "Epoch 54/100\n",
      " - 1s - loss: 2.9558 - accuracy: 0.1922 - val_loss: 3.1504 - val_accuracy: 0.1750\n",
      "Epoch 55/100\n",
      " - 1s - loss: 2.9191 - accuracy: 0.1922 - val_loss: 3.1590 - val_accuracy: 0.1750\n",
      "Epoch 56/100\n",
      " - 1s - loss: 2.9289 - accuracy: 0.1922 - val_loss: 3.1554 - val_accuracy: 0.1750\n",
      "Epoch 57/100\n",
      " - 1s - loss: 2.9209 - accuracy: 0.1922 - val_loss: 3.1494 - val_accuracy: 0.1750\n",
      "Epoch 58/100\n",
      " - 1s - loss: 2.9430 - accuracy: 0.1922 - val_loss: 3.1596 - val_accuracy: 0.1750\n",
      "Epoch 59/100\n",
      " - 1s - loss: 2.9335 - accuracy: 0.1922 - val_loss: 3.2083 - val_accuracy: 0.1750\n",
      "Epoch 60/100\n",
      " - 1s - loss: 2.9147 - accuracy: 0.1922 - val_loss: 3.1910 - val_accuracy: 0.1750\n",
      "Epoch 61/100\n",
      " - 1s - loss: 2.9368 - accuracy: 0.1922 - val_loss: 3.1736 - val_accuracy: 0.1750\n",
      "Epoch 62/100\n",
      " - 1s - loss: 2.9032 - accuracy: 0.1922 - val_loss: 3.1691 - val_accuracy: 0.1750\n",
      "Epoch 63/100\n",
      " - 1s - loss: 2.8917 - accuracy: 0.1922 - val_loss: 3.1724 - val_accuracy: 0.1750\n",
      "Epoch 64/100\n",
      " - 1s - loss: 2.8973 - accuracy: 0.1922 - val_loss: 3.1525 - val_accuracy: 0.1750\n",
      "Epoch 65/100\n",
      " - 1s - loss: 2.9144 - accuracy: 0.1922 - val_loss: 3.1739 - val_accuracy: 0.1750\n",
      "Epoch 66/100\n",
      " - 1s - loss: 2.9053 - accuracy: 0.1922 - val_loss: 3.1628 - val_accuracy: 0.1750\n",
      "Epoch 67/100\n",
      " - 1s - loss: 2.9066 - accuracy: 0.1922 - val_loss: 3.1564 - val_accuracy: 0.1750\n",
      "Epoch 68/100\n",
      " - 1s - loss: 2.9112 - accuracy: 0.1922 - val_loss: 3.1802 - val_accuracy: 0.1750\n",
      "Epoch 69/100\n",
      " - 1s - loss: 2.9019 - accuracy: 0.1922 - val_loss: 3.1818 - val_accuracy: 0.1750\n",
      "Epoch 70/100\n",
      " - 1s - loss: 2.9157 - accuracy: 0.1922 - val_loss: 3.1652 - val_accuracy: 0.1750\n",
      "Epoch 71/100\n",
      " - 1s - loss: 2.8824 - accuracy: 0.1922 - val_loss: 3.1782 - val_accuracy: 0.1750\n",
      "Epoch 72/100\n",
      " - 1s - loss: 2.8993 - accuracy: 0.1922 - val_loss: 3.1653 - val_accuracy: 0.1750\n",
      "Epoch 73/100\n",
      " - 1s - loss: 2.8986 - accuracy: 0.1922 - val_loss: 3.1750 - val_accuracy: 0.1750\n",
      "Epoch 74/100\n",
      " - 1s - loss: 2.8986 - accuracy: 0.1950 - val_loss: 3.1756 - val_accuracy: 0.1750\n",
      "Epoch 75/100\n",
      " - 1s - loss: 2.8917 - accuracy: 0.1922 - val_loss: 3.2022 - val_accuracy: 0.1750\n",
      "Epoch 76/100\n",
      " - 1s - loss: 2.8683 - accuracy: 0.1922 - val_loss: 3.2765 - val_accuracy: 0.1750\n",
      "Epoch 77/100\n",
      " - 1s - loss: 2.8596 - accuracy: 0.1922 - val_loss: 3.1852 - val_accuracy: 0.1750\n",
      "Epoch 78/100\n",
      " - 1s - loss: 2.8577 - accuracy: 0.1922 - val_loss: 3.1787 - val_accuracy: 0.1750\n",
      "Epoch 79/100\n",
      " - 1s - loss: 2.8772 - accuracy: 0.1922 - val_loss: 3.1949 - val_accuracy: 0.1750\n",
      "Epoch 80/100\n",
      " - 1s - loss: 2.8870 - accuracy: 0.1922 - val_loss: 3.1778 - val_accuracy: 0.1750\n",
      "Epoch 81/100\n",
      " - 1s - loss: 2.8672 - accuracy: 0.1950 - val_loss: 3.2285 - val_accuracy: 0.1750\n",
      "Epoch 82/100\n",
      " - 1s - loss: 2.8786 - accuracy: 0.1922 - val_loss: 3.1598 - val_accuracy: 0.1750\n",
      "Epoch 83/100\n",
      " - 1s - loss: 2.8483 - accuracy: 0.1922 - val_loss: 3.2227 - val_accuracy: 0.1750\n",
      "Epoch 84/100\n",
      " - 1s - loss: 2.8575 - accuracy: 0.1922 - val_loss: 3.2294 - val_accuracy: 0.1750\n",
      "Epoch 85/100\n",
      " - 1s - loss: 2.8664 - accuracy: 0.1978 - val_loss: 3.1872 - val_accuracy: 0.1750\n",
      "Epoch 86/100\n",
      " - 1s - loss: 2.8438 - accuracy: 0.1922 - val_loss: 3.1900 - val_accuracy: 0.1750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 1s - loss: 2.8464 - accuracy: 0.1866 - val_loss: 3.2042 - val_accuracy: 0.1750\n",
      "Epoch 88/100\n",
      " - 1s - loss: 2.8433 - accuracy: 0.1978 - val_loss: 3.2301 - val_accuracy: 0.1750\n",
      "Epoch 89/100\n",
      " - 1s - loss: 2.8291 - accuracy: 0.1950 - val_loss: 3.2295 - val_accuracy: 0.1750\n",
      "Epoch 90/100\n",
      " - 1s - loss: 2.8389 - accuracy: 0.2089 - val_loss: 3.3037 - val_accuracy: 0.1750\n",
      "Epoch 91/100\n",
      " - 1s - loss: 2.8281 - accuracy: 0.1950 - val_loss: 3.2278 - val_accuracy: 0.1750\n",
      "Epoch 92/100\n",
      " - 1s - loss: 2.7986 - accuracy: 0.2033 - val_loss: 3.3244 - val_accuracy: 0.1750\n",
      "Epoch 93/100\n",
      " - 1s - loss: 2.8019 - accuracy: 0.2033 - val_loss: 3.2477 - val_accuracy: 0.1750\n",
      "Epoch 94/100\n",
      " - 1s - loss: 2.8078 - accuracy: 0.1950 - val_loss: 3.2863 - val_accuracy: 0.1750\n",
      "Epoch 95/100\n",
      " - 1s - loss: 2.8218 - accuracy: 0.1950 - val_loss: 3.2869 - val_accuracy: 0.1750\n",
      "Epoch 96/100\n",
      " - 1s - loss: 2.8226 - accuracy: 0.1894 - val_loss: 3.2206 - val_accuracy: 0.2000\n",
      "Epoch 97/100\n",
      " - 1s - loss: 2.8013 - accuracy: 0.2006 - val_loss: 3.2222 - val_accuracy: 0.2000\n",
      "Epoch 98/100\n",
      " - 1s - loss: 2.7909 - accuracy: 0.2033 - val_loss: 3.3236 - val_accuracy: 0.1750\n",
      "Epoch 99/100\n",
      " - 1s - loss: 2.7774 - accuracy: 0.2145 - val_loss: 3.3264 - val_accuracy: 0.2000\n",
      "Epoch 100/100\n",
      " - 1s - loss: 2.8052 - accuracy: 0.1978 - val_loss: 3.3346 - val_accuracy: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a04e4212e8>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=input_X, y=input_y, epochs=100, verbose=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Character_based_Language_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(obj=mapped_char, file=open('Character_based_LM_Dictionary.pkl', mode='wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(\"Character_based_Language_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 10, 75)            34200     \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 50)                25200     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 38)                1938      \n",
      "=================================================================\n",
      "Total params: 63,888\n",
      "Trainable params: 63,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = pickle.load(open(\"Character_based_LM_Dictionary.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'Eating honey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 15, 33, 23, 27, 21, 1, 22, 28, 27, 19, 37]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = [dictionary[i] for i in input_text]\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_encode = pad_sequences([encoded_text], maxlen=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_input = to_categorical(padded_encode, num_classes=len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class = loaded_model.predict_classes(to_input, verbose=0)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_chr = \" \"\n",
    "for char, map_index in dictionary.items():\n",
    "    if map_index == pred_class:\n",
    "        out_chr = char\n",
    "        break    \n",
    "        \n",
    "out_chr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_char(model, vocab, seed_text, n_char):\n",
    "    in_text = seed_text\n",
    "    for _ in range(n_char):\n",
    "        encode_text = [vocab[i] for i in in_text]\n",
    "        pad_sequence = pad_sequences([encode_text], maxlen=10, )\n",
    "        to_input = to_categorical(pad_sequence, num_classes=len(vocab))\n",
    "        y_hat = model.predict_classes(to_input, verbose = 0)\n",
    "        out_char = ' '\n",
    "        for char, index in vocab.items():\n",
    "            if index == y_hat:\n",
    "                out_char = char\n",
    "                break\n",
    "                \n",
    "        in_text += out_char\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat lun     '"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'eat lun'\n",
    "generate_char(model=loaded_model, vocab=dictionary, seed_text=text, n_char=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sing a sok lkh   eee    '"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Sing a sok lkh'\n",
    "generate_char(model=loaded_model, vocab=dictionary, seed_text=text, n_char=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
